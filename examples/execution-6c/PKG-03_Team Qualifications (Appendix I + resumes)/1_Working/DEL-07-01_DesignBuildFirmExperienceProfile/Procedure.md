# Procedure: DEL-07-01 Design-Build Firm Experience Profile

## Purpose

### What This Procedure Accomplishes

This procedure defines the process to **produce** the Design-Build Firm Experience Profile deliverable (DEL-07-01) for inclusion in the Penhold Public Services Building RFP response. The procedure ensures:

1. Content meets RFP requirements (Section 7.1.6 - **location TBD**)
2. Firm experience narrative is tailored to Owner Statement of Requirements (OSR)
3. Comparable projects are appropriately selected and documented
4. Content is consistent with sibling deliverables (DEL-07-02 team resumes, DEL-07-03 subtrade list)
5. Deliverable supports the 15-point "Project Team & Firms" evaluation category
6. Quality control and approval checkpoints are completed before final submission

**Source:** Agent protocol Step 4d (Procedure purpose); Decomposition DEL-07-01; _CONTEXT.md

---

## Prerequisites

### Before Beginning Work on This Deliverable

#### Dependencies
- **Dependency tracking mode:** NOT_TRACKED
- **Coordination approach:** Dependencies coordinated externally by humans (see `_DEPENDENCIES.md` and `/Users/ryan/ai-env/projects/chirality-app-test/test/execution-6/_Coordination/_COORDINATION.md`)

**Practical dependencies (not formally tracked):**
- DEL-07-02 (Key Team Members and Resumes) should be developed in parallel to ensure firm experience aligns with proposed team capabilities
- DEL-07-03 (Appendix I Subtrade List) should be developed in parallel to ensure firm capabilities align with proposed subconsultant/subtrade structure
- DEL-01-01 (Compliance Matrix) provides RFP requirements roadmap for firm experience content
- Access to RFP Section 7.1.6/7.1.7 and Appendix A (OSR) - **currently TBD** (PDF not accessible)

**Source:** _DEPENDENCIES.md; **ASSUMPTION** - practical workflow dependencies

#### Reference Materials Required
The following materials must be available before starting work:

| Reference | Location | Purpose |
|-----------|----------|---------|
| **RFP 2024_004 (full document)** | `/Users/ryan/ai-env/projects/chirality-app-test/test/execution-6/_Sources/` | Section 7.1.6 firm experience requirements, Appendix A (OSR) |
| **Addendum 03** | `/Users/ryan/ai-env/projects/chirality-app-test/test/execution-6/_Sources/` | Scope clarifications affecting team/firm requirements |
| **Decomposition Document** | `/Users/ryan/ai-env/projects/chirality-app-test/test/execution-6/_Decomposition/` | Deliverable definition, objectives, scope items, evaluation criteria |
| **Firm project database** | **TBD** - internal firm records | Past Design-Build project details (names, dates, values, scopes, clients) |
| **Client reference contacts** | **TBD** - internal firm records | Current contact information for project references |
| **Firm performance data** | **TBD** - internal firm records | Budget/schedule variance data, safety records, quality metrics |
| **Firm marketing collateral** | **TBD** - internal firm records | Company overview, capability statements, past proposal content (for adaptation) |

**Source:** _REFERENCES.md; **ASSUMPTION** - typical proposal production inputs

#### Team Roles and Responsibilities
| Role | Responsibilities | Person/Team |
|------|------------------|-------------|
| **Lead Author** | Draft firm experience narrative, select comparable projects, coordinate with DEL-07-02/03 authors | Proposal Manager |
| **Technical Reviewer** | Verify project details accuracy, technical credibility | Senior Project Manager or Principal |
| **Data Collector** | Gather project data, contact information, performance metrics from firm records | HR/Team Admin or Proposal Coordinator |
| **Quality Reviewer** | Check RFP compliance, OSR alignment, cross-document consistency | Proposal Manager or Quality Lead |
| **Executive Approver** | Final approval for accuracy, defensibility, competitive positioning | **TBD** - firm executive or leadership |

**Source:** _CONTEXT.md "Responsible: Proposal Manager + HR/Team Admin"; **ASSUMPTION** - typical proposal team structure

#### Tools and Templates
- Word processor (Microsoft Word, Google Docs, or equivalent)
- Spreadsheet tool for project data organization (Excel, Google Sheets)
- Access to firm's project management system or historical project files
- Proposal template/style guide (if firm has standard proposal format)
- Compliance matrix template (from DEL-01-01) for requirement tracking

**Source:** **ASSUMPTION** - typical proposal production tools

---

## Steps

### Step 1: Review RFP Requirements and OSR
**Objective:** Understand what the RFP requires and what the owner values.

**Blocking Dependency Check:**
> **Enrichment Note (A-004):** Step 1 requires RFP Section 7.1.6 to be accessible. If RFP is TBD/inaccessible, this step cannot execute as written. [Source: _SEMANTIC_LENSING.md §Matrix A, Lens A:[normative, reviewing]]

**Pre-step validation:**
- [ ] RFP Section 7.1.6 accessible? If NO: **STOP** - obtain RFP before proceeding, OR proceed with provisional requirements using Specification R-01 through R-05 as placeholder (mark all outputs as "PROVISIONAL - pending RFP validation")
- [ ] RFP Appendix A (OSR) accessible? If NO: Proceed with assumed OSR priorities per Guidance §Value Orientation Clarification (mark OSR tailoring as "ASSUMED - pending OSR validation")

**Actions:**
1.1. Read RFP Section 7.1.6 (firm experience requirements) and note:
   - Required content elements (firm overview, project list, project details)
   - Format requirements (tables, narrative, page limits)
   - Evaluation criteria and scoring approach
   - Any restrictions (e.g., number of projects, time window, project types)

1.2. Read RFP Appendix A (Owner Statement of Requirements - OSR) and identify:
   - Owner priorities (e.g., durability, maintenance, operational efficiency, budget predictability)
   - Owner constraints (e.g., schedule, budget limits, site restrictions)
   - Owner values (e.g., community safety, local experience, innovation)

1.3. Review Addendum 03 for any clarifications affecting firm/team requirements.

1.4. Consult Decomposition §15 (Evaluation Criteria Crosswalk) to understand evaluation weight (15 points) and evaluation context.

1.5. Create a checklist of mandatory content elements and OSR priorities to guide drafting.

**Verification:** Checklist completed and reviewed by Proposal Manager.

**Source:** Specification R-01, R-02; Guidance Principle 3 (OSR alignment); **ASSUMPTION** - proposal development workflow; _SEMANTIC_LENSING.md A-004

---

### Step 2: Establish Team Qualifications Coordination Plan
**Objective:** Ensure DEL-07-01, DEL-07-02, DEL-07-03 are developed coherently.

**Actions:**
2.1. Schedule coordination meeting with DEL-07-02 author (key team resumes) and DEL-07-03 author (subtrade list).

2.2. Create a "team qualifications matrix" (see Guidance Consideration 5 example):
   - List capability areas relevant to Penhold PSB (fire hall design, public works design, municipal Design-Build delivery, specialized systems - exhaust, generator, etc.)
   - For each capability area, identify: firm's relevant project(s), proposed key person(s), and subtrade/consultant(s)

2.3. Agree on terminology conventions (e.g., how to refer to "Design-Build", "Owner", project names, technical systems) to ensure consistency across all three deliverables.

2.4. Establish review touchpoints (e.g., draft review at 50% completion, final consistency check before submission).

2.5. **Coordination Validation (X-002):** Confirm coordination sufficiency using the following checklist:
   - [ ] Team qualifications matrix complete for all capability areas
   - [ ] Terminology conventions documented and agreed
   - [ ] Review touchpoints scheduled in calendar
   - [ ] All three authors have signed off on coordination plan

> **Enrichment Note (X-002):** Step 2.4 previously stated "resolve inconsistencies" without specifying validation method. Coordination validation checklist added to ensure sufficiency is confirmed before proceeding. [Source: _SEMANTIC_LENSING.md §Matrix X, Lens X:[applying, sufficiency]]

**Verification:** Team qualifications matrix completed; coordination validation checklist signed by all three deliverable authors.

**Source:** Guidance Principle 4 (integrated team coherence), Consideration 5 (PKG-03 coordination); **ASSUMPTION** - proposal coordination best practices; _SEMANTIC_LENSING.md X-002

---

### Step 3: Select Comparable Projects
**Objective:** Identify 3-5 projects that best demonstrate firm's capability to deliver Penhold PSB.

**Blocking Dependency Check:**
> **Enrichment Note (C-003):** Step 3.1 requires "firm project database" which is flagged as TBD/not provided. Execution cannot proceed without this data. [Source: _SEMANTIC_LENSING.md §Matrix C, Lens C:[operative, necessity]]

**Pre-step validation:**
- [ ] Firm project database accessible? If NO: **STOP** - obtain historical project data before proceeding, OR define fallback data source (e.g., firm marketing materials, proposal archives, key personnel recollection with subsequent verification)

**Actions:**
3.1. Query firm project database for Design-Build projects (last 10 years - **TBD** time window from RFP) with the following filters:
   - Building type: fire halls, public works facilities, emergency services buildings, municipal operations centers, integrated facilities
   - Client type: municipal government (preferably Alberta; Canada acceptable; international only if exceptional)
   - Delivery method: Design-Build (or Construction Manager at Risk if firm can articulate relevance)
   - Project status: completed (or substantially complete if RFP allows)

3.2. For each candidate project, assess comparability score (1-5 scale) on:
   - Facility type match (5 = integrated fire+public works; 4 = fire hall; 3 = public works; 2 = municipal building; 1 = other)
   - Geographic relevance (5 = Alberta; 4 = other Canadian prairie province; 3 = other Canada; 2 = similar climate zone; 1 = other)
   - Recency (5 = last 3 years; 4 = 3-5 years; 3 = 5-7 years; 2 = 7-10 years; 1 = >10 years)
   - Team continuity (5 = multiple proposed key personnel involved; 4 = one proposed key person involved; 3 = similar team structure; 2 = same firm/office; 1 = different team)
   - Reference availability (5 = strong reference confirmed; 4 = reference available; 3 = reference likely; 2 = reference uncertain; 1 = no reference)

3.3. Calculate total comparability score for each candidate project (sum of 5 factors; max 25 points).

3.4. **Minimum Comparability Score Threshold (B-006):** Select projects with comparability score >= 18/25. Projects scoring <15/25 should be rejected unless no better alternatives exist.
   - If fewer than 3 projects score >=18/25, document rationale for including lower-scoring projects.

> **Enrichment Note (B-006):** Previously no decision rule for cutoff existed; comparability score was advisory. Minimum threshold (>=18/25) established to ensure project selection is objective, not subjective. [Source: _SEMANTIC_LENSING.md §Matrix B, Lens B:[wisdom, necessity]]

3.5. Select top 3-5 projects based on comparability score. Ensure variety if possible (different project types, different owners, different years) to demonstrate breadth.

3.6. **Credential Readiness Verification (X-001):** Before finalizing selection, verify each project is credential-ready:
   - [ ] No legal disputes or claims associated with project
   - [ ] Client reference verified and available
   - [ ] Project data (dates, values, scope) verifiable from contract documents
   - [ ] No confidentiality restrictions on disclosing project details

> **Enrichment Note (X-001):** Previously no credential readiness verification gate existed before drafting. This verification ensures selected projects are defensible in proposal context. [Source: _SEMANTIC_LENSING.md §Matrix X, Lens X:[guiding, necessity]]

3.7. If firm has fewer than 3 highly comparable projects, consider:
   - Including Design-Bid-Build projects with strong facility type match (explain delivery method difference - see Guidance Trade-off 4)
   - Including projects from related building types (e.g., ambulance stations, municipal maintenance facilities) if they demonstrate relevant technical capabilities
   - Acknowledging limited portfolio in that specific area but emphasizing firm's overall municipal/Design-Build experience

**Verification:** Project selection reviewed and approved by Technical Reviewer and Proposal Manager; credential readiness verified for all selected projects.

**Source:** Guidance Principle 1 (relevance over volume), Consideration 1 (comparable project selection); **ASSUMPTION** - project selection methodology; _SEMANTIC_LENSING.md B-006, C-003, X-001

---

### Step 4: Gather Project Data and Verify Accuracy
**Objective:** Collect complete, accurate, defensible data for selected projects.

**Scrutiny Rationale (D-005):**
> **Enrichment Note (D-005):** This step requires thorough scrutiny beyond "accuracy." Understanding why scrutiny matters strengthens commitment to thoroughness. [Source: _SEMANTIC_LENSING.md §Matrix D, Lens D:[operative, reviewing]]

**Why scrutiny is necessary:**
- **Defensibility:** If evaluator disputes a claim, firm must be able to prove it with source documentation
- **Legal exposure:** Inaccurate claims may constitute misrepresentation in a public procurement process
- **Risk mitigation:** Inconsistent data across proposal sections undermines credibility
- **Evaluator verification:** Evaluators may independently verify claims through reference calls or public records

**Actions:**
4.1. For each selected project, gather from firm records:
   - Project name (official name used in contract)
   - Owner name and location
   - Contract value (original and final, if variance is notable)
   - Completion date (substantial completion and final completion)
   - Scope description (building size, key spaces, site work, special systems)
   - Delivery method (Design-Build, CM@Risk, etc.)
   - Key personnel involved (from firm's team)
   - Budget performance (% variance from original contract; context for variance)
   - Schedule performance (% variance from original schedule; context for variance)
   - Safety record (Total Recordable Incident Rate - TRIR, lost-time incidents)
   - Quality outcomes (deficiencies at substantial completion, owner satisfaction)

4.2. Verify data accuracy:
   - Cross-check contract documents for official names, dates, values
   - Confirm completion dates from Certificate of Substantial Completion or similar
   - Verify budget/schedule variance from project close-out reports
   - Confirm key personnel involvement from project org charts or timesheets

4.3. Contact client references:
   - Confirm current contact information (name, title, phone, email)
   - Obtain permission to list as reference (if RFP requires permission)
   - Brief reference on Penhold PSB project scope so they can speak to relevant experience
   - Confirm their availability during RFP evaluation period (if evaluators may call)

**Verification:** All project data verified by Technical Reviewer; reference contacts confirmed by Proposal Coordinator.

**Source:** Specification R-01.3 (project details required); Guidance Principle 2 (evidence-based claims), Consideration 2 (delivery metrics), Consideration 3 (reference management); _SEMANTIC_LENSING.md D-005

---

### Step 5: Draft Firm Overview Section
**Objective:** Provide context for firm's capabilities and Design-Build delivery model.

**Authorship Authority (D-002):**
> **Enrichment Note (D-002):** Steps 5-10 previously did not specify authorship model (who authors? who reviews when?). This mapping clarifies authority. [Source: _SEMANTIC_LENSING.md §Matrix D, Lens D:[operative, applying]]

| Step Component | Author | Reviewer | Approver |
|----------------|--------|----------|----------|
| Firm overview draft | Proposal Manager | Technical Reviewer (accuracy) | N/A (draft stage) |
| Firm overview final | Proposal Manager | Proposal Manager | Executive Approver (Step 10) |

**Actions:**
5.1. Write firm overview (1-2 paragraphs) covering:
   - Firm name, years in business, headquarters/office locations
   - Design-Build delivery model (integrated design-construction, single-point accountability)
   - Municipal/emergency services facility specialization
   - Alberta/regional experience and regulatory knowledge
   - Brief OSR alignment statement (Layer 1 tailoring - see Guidance Consideration 4)

5.2. Keep overview concise—evaluators want to see projects, not lengthy corporate history.

5.3. Ensure terminology aligns with DEL-07-02 and DEL-07-03 (e.g., how firm describes its Design-Build approach, team structure).

**Verification:** Draft reviewed by Proposal Manager for clarity, conciseness, and OSR alignment.

**Source:** Specification R-01.1; Guidance Consideration 4 (Layer 1 OSR tailoring); **ASSUMPTION** - typical firm overview structure; _SEMANTIC_LENSING.md D-002

---

### Step 6: Draft Comparable Projects Descriptions
**Objective:** Present selected projects with appropriate detail and OSR alignment.

**Actions:**
6.1. For each project, write a structured description (format may be table + narrative or narrative with embedded data):
   - **Project identification:** Name, owner, location, completion date, contract value, delivery method
   - **Scope summary:** Building size, key spaces, site work, special systems (1-2 sentences)
   - **Relevance to Penhold PSB:** Explain how this project demonstrates capability for Penhold PSB; highlight similarities in program, scale, complexity, client type (2-3 sentences)
   - **OSR alignment:** Connect project outcomes to OSR priorities (Layer 2 tailoring - see Guidance Consideration 4 and Example 1)
   - **Client reference:** Name, title, organization, contact information (if RFP format allows)

6.2. Use consistent structure for all projects to facilitate evaluator comparison.

6.3. Emphasize Design-Build-specific successes (integrated design-construction value, single-point accountability, risk management) per Guidance Principle 5.

6.4. Include context for any variances (budget, schedule) per Guidance Consideration 2.

**Verification:** Draft reviewed by Technical Reviewer for accuracy; Proposal Manager for OSR alignment and clarity.

**Source:** Specification R-01.3, R-01.4, R-02.1; Guidance Principle 3, Principle 5, Consideration 4; Example 1

---

### Step 7: Draft Delivery Success Narrative
**Objective:** Summarize firm's track record and connect to OSR priorities.

**Actions:**
7.1. Write a delivery success summary (1-2 paragraphs) covering:
   - Overall municipal/Design-Build portfolio summary (number of projects, total value, geographic range)
   - Budget performance (average variance, range, context for variances)
   - Schedule performance (average variance, on-time delivery rate, context for variances)
   - Safety record (TRIR, lost-time incident rate, safety culture)
   - Quality outcomes (deficiency rates, owner satisfaction, post-occupancy performance)

7.2. Connect track record to OSR priorities (Layer 3 tailoring - see Guidance Consideration 4 and Example 3):
   - If OSR emphasizes durability, highlight material selection and long-term performance
   - If OSR emphasizes budget predictability, highlight consistent budget performance and cost management approach
   - If OSR emphasizes schedule certainty, highlight on-time delivery record and risk mitigation

7.3. Use evidence-based claims (cite data sources or explain methodology - e.g., "averaged across 8 municipal projects completed 2018-2024").

**Verification:** Draft reviewed by Technical Reviewer for data accuracy; Proposal Manager for OSR alignment.

**Source:** Specification R-01.5, R-02.1; Guidance Principle 2, Principle 3, Consideration 4; Example 2, Example 3

---

### Step 8: Cross-Document Consistency Check
**Objective:** Ensure DEL-07-01 aligns with DEL-07-02 (team resumes) and DEL-07-03 (subtrade list).

**Actions:**
8.1. Review DEL-07-02 (key team member resumes) and check:
   - Do proposed key personnel have experience on projects listed in DEL-07-01?
   - Are technical capabilities claimed in DEL-07-01 supported by key personnel expertise in DEL-07-02?
   - Is terminology consistent (project names, technical terms, role titles)?

8.2. Review DEL-07-03 (Appendix I subtrade list) and check:
   - Are subconsultants/subtrades listed for capability areas highlighted in DEL-07-01?
   - Are subconsultants' qualifications consistent with firm's claimed experience?

8.3. Resolve any inconsistencies:
   - If DEL-07-01 lists a project but DEL-07-02 shows no key personnel involvement, either remove the project from DEL-07-01 or add personnel involvement detail to DEL-07-02
   - If DEL-07-01 claims capability (e.g., fire protection engineering) but DEL-07-03 does not list a fire protection consultant, add to DEL-07-03 or remove capability claim from DEL-07-01

8.4. Update team qualifications matrix (from Step 2) to reflect final alignment.

8.5. **Internal 4-Document Consistency Check (C-004):** Verify consistency across DEL-07-01's own 4 documents (Datasheet, Specification, Guidance, Procedure):
   - [ ] Datasheet attributes match Specification requirements
   - [ ] Specification requirements are addressed by Guidance principles
   - [ ] Guidance principles are implemented in Procedure steps
   - [ ] No conflicting terminology or assumptions across 4 documents

> **Enrichment Note (C-004):** Step 8 previously checked only inter-deliverable alignment (DEL-07-01/02/03), not intra-deliverable coherence (Datasheet-Spec-Guidance-Procedure). Internal consistency check added. [Source: _SEMANTIC_LENSING.md §Matrix C, Lens C:[operative, completeness]]

**Verification:** Consistency check completed by Proposal Manager; all inconsistencies (inter-deliverable AND intra-deliverable) resolved before proceeding.

**Source:** Specification R-05 (cross-document consistency); Guidance Principle 4, Consideration 5; **ASSUMPTION** - quality control workflow; _SEMANTIC_LENSING.md C-004

---

### Step 9: RFP Compliance and Format Check
**Objective:** Verify deliverable meets all RFP requirements.

**Blocking Dependency Check:**
> **Enrichment Note (A-004):** Step 9.1 requires RFP Section 7.1.6 to be accessible for line-by-line verification. If RFP is TBD/inaccessible, define fallback verification. [Source: _SEMANTIC_LENSING.md §Matrix A, Lens A:[normative, reviewing]]

**Pre-step validation:**
- [ ] RFP Section 7.1.6 accessible? If NO: Use Specification R-01 through R-05 as proxy requirements (mark compliance as "PROVISIONAL - pending RFP validation when accessible")

**Actions:**
9.1. Review RFP Section 7.1.6 requirements line-by-line; confirm each requirement is met in draft.

9.2. Check format compliance:
   - Does content follow RFP section headings and order (per RFP Sections 6-9)?
   - Is page count appropriate (not too brief, not excessive)?
   - Does formatting match proposal template/style guide?

9.3. Check PDF size contribution:
   - Estimate deliverable's contribution to total PDF size (with images/tables)
   - If contribution is large (>1-2MB for this section alone), consider compression or format adjustments
   - Total proposal must be <15MB per Decomposition §3 C-01

9.4. Update compliance matrix (DEL-01-01) to confirm DEL-07-01 addresses required RFP sections.

9.5. **Compliance Matrix Verification and Sign-off (X-004):**
   - [ ] Verify compliance matrix update is accurate (not just completed)
   - [ ] If authors disagree on compliance interpretation, escalate to Proposal Manager for ruling
   - [ ] Sign-off: Compliance matrix verified by _________________ (signature/date)

> **Enrichment Note (X-004):** Step 9.4 previously required compliance matrix update but not verification of that action. Verification with sign-off added to ensure oversight. [Source: _SEMANTIC_LENSING.md §Matrix X, Lens X:[reviewing, consistency]]

**Verification:** Compliance check completed by Proposal Manager; compliance matrix verified and signed; any non-compliance issues resolved.

**Source:** Specification R-04 (format and compliance requirements); Decomposition §3 C-01, C-02; **ASSUMPTION** - quality control workflow; _SEMANTIC_LENSING.md A-004, X-004

---

### Step 10: Quality Review and Approval
**Objective:** Obtain final approval before integrating into submission package.

**Authorship Authority (D-002 continued):**
| Step Component | Author | Reviewer | Approver |
|----------------|--------|----------|----------|
| Quality review findings | Proposal Manager | N/A | N/A |
| Executive review decision | N/A | Executive Approver | Executive Approver |
| Final version | Proposal Manager | Proposal Manager | Executive Approver |

**Actions:**
10.1. Conduct internal quality review:
   - Proofread for grammar, spelling, punctuation
   - Check for clarity and readability
   - Verify all data is accurate and defensible
   - Confirm all claims are evidence-based or appropriately qualified
   - Verify OSR alignment is clear and compelling

10.2. Conduct executive review:
   - Present draft to firm leadership or designated approver
   - Confirm firm is comfortable with all project descriptions, metrics, and claims
   - Obtain approval for competitive positioning (is this our strongest content?)
   - Address any concerns or requested revisions

10.3. **Worth Adjudication Rubric for Executive Review (D-003):**

> **Enrichment Note (D-003):** Executive review previously asked "is this our strongest content?" without a rubric. Worth adjudication criteria added for objective assessment. [Source: _SEMANTIC_LENSING.md §Matrix D, Lens D:[evaluative, judging]]

| Worth Criterion | Assessment Question | Target Score |
|-----------------|---------------------|--------------|
| **Competitive positioning** | Does this content position us favorably against likely competitors? | Strong/Adequate/Weak |
| **Risk exposure** | Are there any claims that could be challenged or disproven? | None/Minor/Major |
| **OSR alignment strength** | Does the narrative explicitly connect to OSR priorities? | Explicit/Implicit/Missing |
| **Evaluation scoring potential** | Based on self-score, what evaluation points are likely? | >=12/15, 10-12/15, <10/15 |
| **Differentiation** | Does anything in this content stand out from a typical proposal? | Strong/Adequate/Weak |

**Executive review decision:** Approve / Revise / Reject (with rationale documented)

10.4. Finalize draft:
   - Incorporate all review comments and revisions
   - Conduct final proofread
   - Lock version control (mark as "FINAL FOR SUBMISSION")

10.5. Deliver to DEL-01-02 author (Final Submission Package) for integration into proposal PDF.

**Verification:** Final approval signature/email from Executive Approver; worth adjudication rubric completed; deliverable handed off to submission coordinator.

**Source:** **ASSUMPTION** - proposal approval workflow; Decomposition §3 C-03 (proper execution required); _SEMANTIC_LENSING.md D-002, D-003

---

## Verification

### Step-by-Step Verification Checkpoints

| Step | Verification Activity | Responsible | Acceptance Criteria |
|------|----------------------|-------------|---------------------|
| **Step 1** | RFP requirements checklist complete | Proposal Manager | All mandatory content elements identified; OSR priorities listed |
| **Step 2** | Team qualifications matrix complete | Proposal Manager + DEL-07-02/03 authors | All capability areas mapped to firm/people/subtrades |
| **Step 3** | Project selection approved | Technical Reviewer + Proposal Manager | 3-5 comparable projects selected with documented rationale |
| **Step 4** | Project data verified | Technical Reviewer + Proposal Coordinator | All data cross-checked to source documents; references confirmed |
| **Step 5** | Firm overview drafted | Proposal Manager | Overview is concise, OSR-aligned, and terminology-consistent |
| **Step 6** | Project descriptions drafted | Technical Reviewer + Proposal Manager | All projects have complete data, OSR alignment, and Design-Build emphasis |
| **Step 7** | Delivery success narrative drafted | Technical Reviewer + Proposal Manager | Narrative is evidence-based and OSR-aligned |
| **Step 8** | Cross-document consistency verified | Proposal Manager | No unresolved inconsistencies with DEL-07-02 or DEL-07-03 |
| **Step 9** | RFP compliance confirmed | Proposal Manager | All RFP requirements met; format compliant; PDF size acceptable |
| **Step 10** | Executive approval obtained | Executive Approver | Final draft approved for submission |

**Source:** Agent protocol Step 4d (Procedure verification); **ASSUMPTION** - quality control checkpoints

---

### Final Deliverable Acceptance Criteria

The DEL-07-01 deliverable is accepted for submission when:

1. **Content completeness:** All Specification requirements (R-01 through R-05) are met or explicitly noted as **TBD** with mitigation plan
2. **OSR alignment:** Content is demonstrably tailored to Owner Statement of Requirements (Layers 1-3 approach)
3. **Cross-document consistency:** No unresolved conflicts with DEL-07-02 (team resumes) or DEL-07-03 (subtrade list)
4. **Data accuracy:** All project data is verified and defensible; references confirmed
5. **RFP compliance:** Content follows RFP section order and format; contributes appropriately to 15MB PDF limit
6. **Quality standard:** Content is clear, professional, error-free, and competitively positioned
7. **Executive approval:** Firm leadership has approved content for submission

**Source:** _CONTEXT.md acceptance criteria; Specification §Verification; Agent protocol SPEC §Document Set Validity

---

## Records

### Documentation Produced by This Procedure

| Record | Purpose | Format | Retention |
|--------|---------|--------|-----------|
| **DEL-07-01 Draft (final)** | Primary deliverable for integration into proposal PDF | Word/PDF | Through contract award + contract period + **TBD** (warranty/claims period) |
| **RFP Requirements Checklist** | Compliance tracking | Spreadsheet or checklist document | Through proposal submission + **TBD** |
| **Team Qualifications Matrix** | Coordination tool for DEL-07-01/02/03 alignment | Spreadsheet | Through proposal submission |
| **Project Data Verification Records** | Source documentation for project details, budget/schedule metrics, references | Spreadsheet + supporting documents | Through contract award + **TBD** (defensibility period) |
| **Review Comments and Resolutions** | Quality control audit trail | Email, markup documents, or review log | Through proposal submission |
| **Executive Approval Record** | Approval signature or email | Email or approval form | Through contract award + **TBD** |
| **Version Control Log** | Track draft revisions and final version | Document metadata or version log | Through proposal submission |

**Source:** **ASSUMPTION** - typical proposal documentation and retention practices

---

### Handoff to Next Process

Upon completion of this procedure:

1. **Deliverable handoff:** Provide final DEL-07-01 document (Word/PDF) to DEL-01-02 author (Final Submission Package) for integration into proposal PDF.

2. **Compliance matrix update:** Confirm with DEL-01-01 author (Compliance Matrix) that DEL-07-01 addresses all required RFP sections.

3. **Coordination confirmation:** Confirm with DEL-07-02 and DEL-07-03 authors that all three PKG-03 deliverables are aligned and ready for submission.

4. **Archive:** Store all working files, verification records, and approval records in proposal archive for future reference.

**Source:** **ASSUMPTION** - proposal workflow handoffs; Decomposition §7 PKG-01 final submission coordination

---

## Evaluative Audit Checklist

> **Enrichment Note (F-004):** Guidance §Principle 1 assumes evaluator constraints; Specification §R-02.2 requires evaluation criteria alignment; Procedure §Step 9 verifies compliance but not evaluation scoring alignment. This unified checklist integrates evaluative command across all three documents. [Source: _SEMANTIC_LENSING.md §Matrix F, Lens F:[evaluative, consistency]]

| Audit Item | Source Authority | Verification Activity | Status |
|------------|------------------|----------------------|--------|
| **Evaluator time constraints respected** | Guidance Principle 1 | Content is concise; 3-5 projects highlighted | [ ] Pass / [ ] Fail |
| **Evidence-based claims** | Guidance Principle 2 | All metrics verifiable from source documents | [ ] Pass / [ ] Fail |
| **OSR alignment explicit** | Guidance Principle 3; Specification R-02.1 | Each project description connects to OSR priority | [ ] Pass / [ ] Fail |
| **Design-Build emphasis** | Guidance Principle 5 | DB-specific successes highlighted for each project | [ ] Pass / [ ] Fail |
| **Evaluation criteria addressed** | Specification R-02.2 | 15-point category criteria explicitly addressed | [ ] Pass / [ ] Fail |
| **Self-score performed** | Specification §Verification | Self-score >=12/15 achieved | [ ] Pass / [ ] Fail |
| **RFP compliance verified** | Procedure Step 9 | Compliance matrix signed | [ ] Pass / [ ] Fail |

---

**Document Status:** Pass 3 generated (Semantic Lensing Enrichment incorporated; 12 warranted items addressed: A-004, B-006, C-003, C-004, D-002, D-003, D-005, X-001, X-002, X-004, F-004)
