name: Frontend CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Environment and dependency validation
  validate:
    runs-on: ubuntu-latest
    name: Validate Environment & Dependencies
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version-file: '.nvmrc'
        cache: 'npm'
        cache-dependency-path: 'package-lock.json'
        cache-dependency-path: 'package-lock.json'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate environment configuration
      run: npm run env:check
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        
  # Code quality checks
  quality:
    runs-on: ubuntu-latest
    name: Code Quality & Standards
    needs: validate
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version-file: '.nvmrc'
        cache: 'npm'
        cache-dependency-path: 'package-lock.json'
        cache-dependency-path: 'package-lock.json'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run ESLint
      run: npm run lint
      
    - name: Run TypeScript type checking
      run: npm run type-check
      
    - name: Update documentation index
      run: npm run update-docs-index
      
    - name: Check for documentation changes
      run: |
        if ! git diff --quiet docs/FRONTEND_DOCUMENTATION_INDEX.md; then
          echo "Documentation index was updated during CI run (expected behavior)."
          echo "This indicates the pre-commit hook updated timestamps."
          git diff docs/FRONTEND_DOCUMENTATION_INDEX.md
          echo "✅ Documentation generation working correctly"
        else
          echo "✅ Documentation index is up to date"
        fi

  # Build and test
  build-test:
    runs-on: ubuntu-latest
    name: Build & Test Application
    needs: quality
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version-file: '.nvmrc'
        cache: 'npm'
        cache-dependency-path: 'package-lock.json'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build application
      run: npm run build
      env:
        NEXT_PUBLIC_APP_NAME: "Chirality Chat CI"
        NEXT_PUBLIC_DEBUG: "0"
        NEXT_TELEMETRY_DISABLED: "1"
        
    # Debug step removed after path issues resolved
        
    - name: Create sample run for artifact testing
      run: |
        echo "Creating sample run for ZIP artifact..."
        mkdir -p test-runs/sample-run
        
        # Create sample run.json and packets.jsonl
        cat > test-runs/sample-run/run.json << 'EOF'
        {
          "runId": "run_test_ci_sample",
          "timestamp": "2024-01-01T00:00:00.000Z",
          "problemStatement": "CI test problem for artifact validation",
          "totalDuration": 1234,
          "totalTokens": 567,
          "mode": "foundation",
          "status": "completed"
        }
        EOF
        
        cat > test-runs/sample-run/packets.jsonl << 'EOF'
        {"id":"packet_s1","createdAt":"2024-01-01T00:00:00.000Z","station":"S1","modality":"problem","payload":{"J":"Sample problem analysis"}}
        {"id":"packet_s2","createdAt":"2024-01-01T00:00:01.000Z","station":"S2","modality":"systematic","payload":{"DS":"Sample data sheet"}}
        {"id":"packet_s11","createdAt":"2024-01-01T00:00:05.000Z","station":"S11","modality":"resolution","payload":{"Final":"Sample resolution"}}
        EOF
        
        # Create ZIP of the sample run
        cd test-runs/sample-run
        zip -r ../sample-run.zip .
        cd ../..
        
        echo "✓ Sample run ZIP created: test-runs/sample-run.zip"
        ls -la test-runs/
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: next-build
        path: |
          ${{ github.workspace }}/.next/standalone
          ${{ github.workspace }}/.next/static
          ${{ github.workspace }}/public
          ${{ github.workspace }}/package.json
        if-no-files-found: error
        retention-days: 7
        
    - name: Upload sample run artifact
      uses: actions/upload-artifact@v4
      with:
        name: sample-run-zip
        path: ${{ github.workspace }}/test-runs/sample-run.zip
        if-no-files-found: error
        retention-days: 7
        
    - name: Run tests
      run: npm test
      
    - name: Validate sample run and packet schema
      run: |
        echo "Creating sample traversal run for schema validation..."
        
        # Create validation script
        cat > validate-schema.js << 'EOF'
        import { createOrchestrator } from './src/core/orchestrator.js';
        import { promises as fs } from 'fs';
        import Ajv from 'ajv';
        import addFormats from 'ajv-formats';
        
        async function validateSchema() {
          // Test with fallback mode - no API key needed for foundation mode
          console.log('Creating orchestrator in fallback mode...');
          
          try {
            // Use allowFallback to enable foundation mode without valid API key
            const orchestrator = await createOrchestrator('test-key-for-schema-validation', true);
            
            console.log('Running foundation traversal...');
            const result = await orchestrator.runTraversal({
              title: 'CI Test Problem',
              statement: 'Test problem for CI validation'
            }, { 
              mode: 'foundation',
              exportRun: false 
            });
            
            console.log('✓ Sample run generated successfully');
            console.log(`  - Run ID: ${result.runId}`);
            console.log(`  - Packets: ${result.packets.length}`);
            console.log(`  - Resolution length: ${result.resolution.length} chars`);
            
            if (result.packets.length === 0) {
              console.error('❌ No packets generated - cannot validate schema');
              process.exit(1);
            }
            
            // Validate packets against schema using AJV
            console.log('Loading packet schema...');
            const schemaData = await fs.readFile('./schemas/packet.json', 'utf8');
            const schema = JSON.parse(schemaData);
            
            const ajv = new Ajv({ strict: false });
            addFormats(ajv);
            
            const validate = ajv.compile(schema);
            
            console.log('Validating packets against schema...');
            for (const [i, packet] of result.packets.entries()) {
              if (!validate(packet)) {
                console.error(`❌ Packet ${i+1} (${packet.station}) validation failed:`, validate.errors);
                console.error('Packet data:', JSON.stringify(packet, null, 2));
                process.exit(1);
              }
              console.log(`✓ Packet ${i+1} (${packet.station}, ${packet.modality}) validates`);
            }
            
            console.log(`✓ All ${result.packets.length} packets pass schema validation`);
            console.log('✓ CI schema validation PASSED - real packets validated');
            
          } catch (error) {
            console.error('❌ Schema validation failed with error:', error.message);
            console.error('Full error:', error);
            process.exit(1);
          }
        }
        
        validateSchema().catch(console.error);
        EOF
        
        # Run with tsx for TypeScript support
        npx tsx validate-schema.js
        
        # Clean up
        rm validate-schema.js
      
    - name: Test orchestration system (if API key available)
      if: env.OPENAI_API_KEY != ''
      run: npm run orchestrate:test
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        OPENAI_MODEL: ${{ vars.OPENAI_MODEL || 'gpt-4.1-nano' }}
        
    - name: Debug build output
      run: |
        echo "Current working directory:"
        pwd
        echo "Directory contents:"
        ls -la
        echo "Looking for .next directory:"
        ls -la .next || echo ".next directory not found"
        echo "Looking for any build output:"
        find . -name "*.next*" -o -name "build" -o -name "dist" -o -name "out" | head -10
        
    - name: Pre-upload debug
      run: |
        echo "=== PRE-UPLOAD DEBUG ==="
        echo "Current working directory:"
        pwd
        echo "Full directory listing:"
        ls -la
        echo "Does .next exist?"
        [ -d .next ] && echo "YES: .next directory exists" || echo "NO: .next directory does not exist"
        echo "Contents of .next (if exists):"
        ls -la .next/ 2>/dev/null || echo "Cannot list .next contents"
        echo "========================="

  # Performance and accessibility checks
  performance:
    runs-on: ubuntu-latest
    name: Performance & Accessibility
    needs: build-test
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version-file: '.nvmrc'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: next-build
        path: ${{ github.workspace }}
        
    # Removed debug step after artifact path stabilization
        
    - name: Start standalone server
      env:
        PORT: 3000
        HOSTNAME: 0.0.0.0
        NODE_ENV: production
      run: |
        nohup node .next/standalone/server.js >/dev/null 2>&1 &
        for i in {1..30}; do
          curl -fsS http://localhost:3000 && echo "Server is ready!" && break
          echo "Attempt $i: Server not ready yet, waiting..."
          sleep 1
        done || (echo "Server did not become ready" && exit 1)
        
    - name: Test health endpoint
      run: npm run health
      
    - name: Run Lighthouse CI (if configured)
      if: false  # Enable when Lighthouse config is added
      run: npx lhci autorun
      
  # Security scanning
  security:
    runs-on: ubuntu-latest
    name: Security Scan
    needs: validate
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version-file: '.nvmrc'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run npm audit
      run: npm audit --audit-level=moderate
      
    - name: Run security scan with CodeQL (if enabled)
      if: false  # Enable when needed
      uses: github/codeql-action/analyze@v3
      with:
        languages: javascript

  # Legacy code sweep
  legacy-sweep:
    runs-on: ubuntu-latest
    name: Legacy Code Sweep
    needs: validate
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Sweep for legacy references
      run: |
        echo "🔍 Scanning for legacy code references..."
        
        # Define legacy patterns to detect
        PATTERNS=(
          "finals"
          "three-pass" 
          "runCompatibilityMode"
          "NEW_PIPELINE_ENABLED"
          "V1\\b"
          "V2\\b" 
          "V3\\b"
          "four-phase agent"
        )
        
        FOUND_ISSUES=false
        
        for pattern in "${PATTERNS[@]}"; do
          echo "Checking for pattern: $pattern"
          
          # Use ripgrep to find patterns, excluding node_modules and archive
          if command -v rg >/dev/null 2>&1; then
            RESULTS=$(rg -n "$pattern" -g '!node_modules' -g '!archive' -g '!.git' . || true)
          else
            # Fallback to grep if ripgrep not available
            RESULTS=$(grep -rn "$pattern" --exclude-dir=node_modules --exclude-dir=archive --exclude-dir=.git . || true)
          fi
          
          if [ -n "$RESULTS" ]; then
            echo "❌ Found legacy pattern '$pattern':"
            echo "$RESULTS"
            echo ""
            FOUND_ISSUES=true
          else
            echo "✅ No instances of '$pattern' found"
          fi
        done
        
        if [ "$FOUND_ISSUES" = true ]; then
          echo ""
          echo "❌ Legacy sweep FAILED - found legacy code references"
          echo "Please remove or update the legacy code patterns listed above."
          exit 1
        else
          echo ""
          echo "✅ Legacy sweep PASSED - no legacy code references found"
        fi
        
    - name: Check for archived legacy code
      run: |
        echo "📦 Checking archived legacy code..."
        
        if [ -d "archive/legacy" ]; then
          ARCHIVE_SIZE=$(du -sh archive/legacy/ | cut -f1)
          ARCHIVE_FILES=$(find archive/legacy/ -type f | wc -l)
          echo "✅ Legacy code properly archived:"
          echo "   - Size: $ARCHIVE_SIZE"
          echo "   - Files: $ARCHIVE_FILES"
          echo "   - Location: archive/legacy/"
        else
          echo "ℹ️  No archived legacy code found (archive/legacy/ directory does not exist)"
        fi

  # Deployment preview (for pull requests)
  preview:
    runs-on: ubuntu-latest
    name: Deploy Preview
    needs: [quality, build-test]
    if: github.event_name == 'pull_request' && github.head_ref != 'main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version-file: '.nvmrc'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: next-build
        path: ${{ github.workspace }}
        
    - name: Debug downloaded artifacts
      run: |
        echo "Downloaded artifact contents:"
        ls -la "$GITHUB_WORKSPACE"
        ls -la "$GITHUB_WORKSPACE/.next/standalone" || echo "No .next/standalone directory found"
        ls -la "$GITHUB_WORKSPACE/.next/static" || echo "No .next/static directory found"
        ls -la "$GITHUB_WORKSPACE/public" || echo "No public directory found"
        
    - name: Deploy to preview environment
      if: false  # Enable when preview environment is configured
      run: echo "Deploy to preview environment would happen here"
      
    - name: Comment PR with preview link
      if: false  # Enable when preview environment is configured
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: '🚀 Preview deployment is ready!'
          })

  # Notification and status reporting
  status:
    runs-on: ubuntu-latest
    name: Report Status
    needs: [validate, quality, build-test, legacy-sweep]
    if: always()
    
    steps:
    - name: Report success
      if: needs.validate.result == 'success' && needs.quality.result == 'success' && needs.build-test.result == 'success' && needs.legacy-sweep.result == 'success'
      run: |
        echo "✅ All CI checks passed successfully!"
        echo "✅ Environment validation: passed"
        echo "✅ Code quality checks: passed" 
        echo "✅ Build and tests: passed"
        echo "✅ Legacy code sweep: passed"
        echo ""
        echo "🎉 Pipeline ready for deployment!"
        
    - name: Report failure
      if: needs.validate.result == 'failure' || needs.quality.result == 'failure' || needs.build-test.result == 'failure' || needs.legacy-sweep.result == 'failure'
      run: |
        echo "❌ CI checks failed!"
        echo "❌ Environment validation: ${{ needs.validate.result }}"
        echo "❌ Code quality checks: ${{ needs.quality.result }}"
        echo "❌ Build and tests: ${{ needs.build-test.result }}"
        echo "❌ Legacy code sweep: ${{ needs.legacy-sweep.result }}"
        echo ""
        echo "Please fix the failing checks before proceeding."
        exit 1
