# UNSAID.md
*The Quiet Part Out Loud: Risks, Fears, and the Erosion of Practice*

While the official documents (`PROFESSIONAL_ENGINEERING.md`, `POSITION_STATEMENT.md`) define *how* we will work, this document captures the darker, systemic risks that we must guard against but rarely put in client proposals.

## 1. The Junior Engineer Problem (The "Missing Rungs")
If Type 2 (Specialist) Agents successfully automate the "grinding" tasks—extracting data, formatting specs, running standard calcs—how do we train the next generation of Senior Engineers?
* **The Risk:** Senior judgment is built on a decade of doing the "boring stuff." If we remove the boring stuff, we remove the training ground.
* **The Unsaid Consequence:** We may be building a "hollow top" profession: a few gray-haired wizards managing an army of bots, with no one coming up behind them to take the wheel.

## 2. The Verification Trap (Cognitive Atrophy)
We claim "Human-at-the-Gate," but human nature is lazy. If the Agent produces an output that looks 99% perfect, 99% of the time, the human reviewer *will* stop reading closely.
* **The Risk:** "Review" becomes a rubber stamp. The engineer *feels* in control but has actually ceded judgment to the machine's plausibility.
* **The Unsaid Consequence:** The first major "AI Engineering Disaster" won't be because the AI went rogue; it will be because a human stopped paying attention and signed a convincing hallucination.

## 3. The "Zombie" Project State
By treating "Filesystem as State," we create a massive, detailed audit trail. But if that trail is generated by agents at 100x human speed, who can actually read it?
* **The Risk:** We create "Write-Only" documentation. Perfect provenance that no human has the bandwidth to trace.
* **The Unsaid Consequence:** We might create systems so complex that they are technically "auditable" but practically "incomprehensible."

## 4. The Economic Squeeze
We argue for "Architecture and Safety," which costs time and money to set up. The market wants "Magic and Speed."
* **The Risk:** Bad actors will use "unsafe" AI to underbid rigorous firms. They will produce designs 50% cheaper by skipping the verification loops.
* **The Unsaid Consequence:** There will be a "Race to the Bottom" on safety margins until a catastrophe forces regulation. We are trying to self-regulate before the bodies pile up.

## 5. The Loss of Serendipity
Engineering isn't just optimization; it's often about noticing the odd thing that "doesn't look right" while you're doing the mundane work.
* **The Risk:** If an agent filters the data for us, we only see what we told it to look for. We lose the peripheral vision that catches the "unknown unknowns."