# CHIRALITY AI

## Position Statement

### Engineering in the Age of Artificial Agency

_February 2026_

---

Professional engineering is a regulated, high-stakes discipline. The work can affect life safety, the environment, critical infrastructure, and public trust. In that context, the central obligations of the profession are unchanged: **duty of care**, **competence**, **independent professional judgment**, **traceability**, and **accountable decision-making**.

Artificial intelligence can accelerate parts of engineering work, but it cannot inherit those obligations. The current technology narrative treats AI as a "digital colleague" that will automate away the drudgery of practice. We reject this personification. In regulated engineering, AI is not a colleague. It is a **cognitive engine** that must be integrated through rigorous, governance-first engineering.

**Our position is simple: Agency is an Engineering Discipline.**

---

## 1  We Build Systems, Not Chatbots

An LLM is to an agent what a combustion engine is to a vehicle: essential, powerful, but dangerous without a steering mechanism, brakes, and a transmission. "Agentic" is not a model feature and not an excuse. It is a **system property**: state, control logic, tools, and environment, composed deliberately.

We build the chassis. We design closed-loop workflows where state is explicit, actions are bounded and typed, validators enforce invariants at every gate, and recovery is deterministic. We structure what can be structured and reserve agent cognition for genuine uncertainty—never for tasks that belong to schemas, checklists, or code.

## 2  Evidence Over Plausibility

Generative AI optimizes for *plausibility*—making things sound right. Professional engineering optimizes for *truth*—making things stand up. In regulated practice, a confident answer without traceable evidence is worse than "I don't know."

We force our systems to cite their work. Unknowns must remain UNKNOWN or TBD—never silently resolved. Assumptions must be labeled. Conflicts must be surfaced. We value a messy, accurate truth over a polished, plausible lie. Every output must be diffable, attributable, and reviewable, with clear lines of accountability.

## 3  Accountability Stays Human

We are clear-eyed about liability. If a bridge fails, the LLM provider will not face consequences. The Engineer of Record will. Therefore, the engineer must retain total authority over every reliance decision.

Our systems are designed to **serve the decision-maker**, not replace them. Agents draft, sort, check, and propose. Humans decide, sign, and seal. No AI system may certify, approve, or issue work for reliance. High-stakes outputs require review and approval by an accountable professional role—Engineer of Record or equivalent—before they leave the system.

## 4  Auditability Is Architecture, Not Paperwork

Deliverables and decisions must be reproducible, reviewable, and durable. The project record must live in controlled artifacts—files, registers, logs—under version control. Not in an opaque chat history. Not in vendor memory. Not in a black box.

We design for the audit that will come in five years, not the demo that ships tomorrow. Every reliance decision carries an evidence pack: the inputs that were used, the reasoning that was applied, the assumptions that were made, and the professional who accepted the result.

## 5  Least Privilege and Data Minimization by Default

File access in engineering practice implies security and privacy obligations. We design narrow action surfaces, scoped permissions, and transparent release processes. Behavior changes are versioned, reviewable, and testable. We treat every expansion of an agent's capability surface as a design decision that requires justification, not a feature that ships by default.

---

## The Path Forward

The right question is not "can AI write engineering documents?" The right question is: **can AI be integrated in a way that preserves professional duty, traceability, and safety?**

We believe the answer is yes—if AI is integrated through governance-first engineering:

- Define decision rights and review gates before any agent touches a deliverable.
- Pre-structure what can be validated: schemas, registers, checklists, typed actions.
- Reserve open-ended reasoning for genuine uncertainty—not for tasks that belong to deterministic code.
- Require evidence packs for every reliance decision.
- Monitor, recover, and improve over time—treating agent failures as engineering defects, not surprises.

---

## Our Commitments

| Commitment | Description |
|---|---|
| **Safety & Compliance** | Non-negotiable adherence to legal, ethical, and regulatory standards. No shortcut, no override, no excuse. |
| **Transparency** | All AI-driven outputs are traceable, verifiable, and open to professional review. The system explains itself or it does not ship. |
| **Augmentation** | AI enhances professional judgment. It does not replace it. Tools assist. Tools cannot hold responsibility. |
| **Security** | Least privilege, scoped access, and data minimization are defaults—not afterthoughts. |

---

The future of engineering is not about pushing a button to get a design. It is about managing the complexity of modern infrastructure with tools that match the scale of the problem. By constraining AI with the rigorous standards of professional practice, we do not limit its power—we unlock its utility for the real world.

**We do not automate engineering judgment. We engineer a harness that allows judgment to scale—without compromising professional responsibility.**

*Chirality AI — Engineering the Art of Control*
