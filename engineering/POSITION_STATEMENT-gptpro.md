# Position Statement
_Date: 2026-02-09_

## Engineering with Artificial Intelligence in Regulated Practice

Professional engineering is a regulated, high‑stakes discipline. The work can affect life safety, the environment, property, and public trust. In that context, the central obligations are unchanged:

- **duty of care**
- **competence**
- **independent professional judgment**
- **traceability and verification**
- **accountable decision‑making**

Artificial intelligence can accelerate parts of engineering work, but it cannot inherit those obligations. **The engineer remains responsible.**

### Our position

1) **AI is a controlled tool inside an engineered system.**  
   “Agentic” is not an excuse and not a claim about a model. Agency is a **system property**: state + control + tools + environment. We build closed-loop workflows with explicit boundaries, validators, monitoring, and recovery.

2) **Evidence beats plausibility.**  
   In regulated engineering, a confident answer without traceable evidence is worse than “I don’t know.” Unknowns must remain UNKNOWN/TBD, assumptions must be labeled, and conflicts must be surfaced—not silently resolved.

3) **Accountability stays human.**  
   High-stakes outputs require review and approval by an accountable professional role (Engineer‑of‑Record or equivalent). No AI system may certify, sign, seal, approve, or issue work for reliance.

4) **Auditability is architecture, not paperwork.**  
   Deliverables and decisions must be reproducible, reviewable, and durable. The project record must live in controlled artifacts (files, registers, logs) under version control—not in an opaque chat history or vendor memory.

5) **Least privilege and data minimization are default.**  
   File access implies security and privacy obligations. We design narrow action surfaces, scoped permissions, and transparent releases so behavior changes are versioned, reviewable, and trustworthy.

### The path forward

The right question is not “can AI write engineering documents?”  
The right question is: **can AI be integrated in a way that preserves professional duty, traceability, and safety?**

We believe the answer is yes—if AI is integrated through **governance-first engineering**:

- define decision rights and review gates
- pre-structure what can be validated (schemas, registers, checklists)
- reserve open-ended reasoning for genuine uncertainty
- require evidence packs for every reliance decision
- monitor and recover from failures over time

**We do not automate engineering judgment. We engineer a harness that allows judgment to scale—without compromising professional responsibility.**
