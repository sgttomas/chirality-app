# Position Statement — Chirality AI on Professional Engineering

Engineering is not content production. It is the disciplined application of judgment under uncertainty, carried out by accountable professionals with a legal duty of care to the public.

Agentic systems are not new to engineering. Engineering teams have always been multi-agent systems: specialists executing bounded scope, leads orchestrating and integrating, principals maintaining alignment between intent and execution. What LLMs change is the cost of perception, reasoning, and communication within these structures — not the structures themselves.

The prevailing narrative treats AI as a productivity tool for engineers: faster documents, automated drafts, generated reports. This framing is dangerous in regulated practice because it obscures the question that actually matters: **does the integration preserve accountability, traceability, independent judgment, and duty of care?**

Chirality is built on the position that it does — but only if the system is designed for it.

Our framework makes the architecture of responsibility explicit. Human decision rights are enumerated and non-negotiable. Agent write scopes are constrained and auditable. Every output carries provenance. Conflicts are surfaced, never silently resolved. The project record is the filesystem, under version control, reviewable at any revision. Agent outputs are drafts and structured assistance — the engineer's review, judgment, and acceptance are what make them engineering work products.

This is not a philosophical position. It is a professional requirement, encoded in software.

The frameworks and norms established now will shape how regulators, insurers, and courts evaluate AI-assisted engineering work for decades. Those norms should be set by practicing engineers who understand what actually goes wrong on real projects — not by the technology industry's productivity narrative.

Chirality exists to set those terms from inside the profession.
